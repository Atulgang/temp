{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/atulgang/Thesis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-03 21:59:52,372 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import glob2\n",
    "from itertools import chain\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cPickle as pickle\n",
    "from  scipy.stats import rankdata\n",
    "import copy\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.compat import range\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "from scipy.stats import hmean\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# WordNet only cares about 5 parts of speech.\n",
    "# The other parts of speech will be tagged as nouns.\n",
    "\n",
    "part = {\n",
    "    'N' : 'n',\n",
    "    'V' : 'v',\n",
    "    'J' : 'a',\n",
    "    'S' : 's',\n",
    "    'R' : 'r'\n",
    "}\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def convert_tag(penn_tag):\n",
    "    '''\n",
    "    convert_tag() accepts the **first letter** of a Penn part-of-speech tag,\n",
    "    then uses a dict lookup to convert it to the appropriate WordNet tag.\n",
    "    '''\n",
    "    if penn_tag in part.keys():\n",
    "        return part[penn_tag]\n",
    "    else:\n",
    "        # other parts of speech will be tagged as nouns\n",
    "        return 'n'\n",
    "\n",
    "\n",
    "def tag_and_lem(element):\n",
    "    '''\n",
    "    tag_and_lem() accepts a token list, tags, converts tags,\n",
    "    lemmatizes, and returns a string\n",
    "    '''\n",
    "    # list of tuples [('token', 'tag'), ('token2', 'tag2')...]\n",
    "    sent = pos_tag(element) # must tag in context\n",
    "    return [ wnl.lemmatize(sent[k][0], convert_tag(sent[k][1][0])) for k in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignores everything except english alphabet and  \n",
    "def only_alphabet(text):\n",
    "    return ''.join(i for i in text if (ord(i)<123 and ord(i)>96) or (ord(i)<91 and ord(i)>64) or ord(i)==32) \n",
    "\n",
    "full_filenames = []\n",
    "x= ['LegalAdhocTask/ConsumerCourtAdhocdata/DCDRC/**/*.txt','LegalAdhocTask/ConsumerCourtAdhocdata/NCDRC/**/*.txt','LegalAdhocTask/ConsumerCourtAdhocdata/SCDRC/**/*.txt', 'LegalAdhocTask/SC-HCAdhocData/DelhiHC/**/*.txt','LegalAdhocTask/SC-HCAdhocData/JharkhandHC/**/*.txt', 'LegalAdhocTask/SC-HCAdhocData/JodhpurHC/**/*.txt' ,'LegalAdhocTask/SC-HCAdhocData/KolkataHC/**/*.txt', 'LegalAdhocTask/SC-HCAdhocData/SupremeCourt/**/*.txt']\n",
    "for glob_filenames in x:\n",
    "    glob_filenames = os.path.normpath(glob_filenames)\n",
    "    for filename in sorted(glob2.glob(glob_filenames)):\n",
    "        full_filenames.append(filename)\n",
    "            \n",
    "filenames = []\n",
    "x= ['LegalAdhocTask/ConsumerCourtAdhocdata/DCDRC/**/*.txt','LegalAdhocTask/ConsumerCourtAdhocdata/NCDRC/**/*.txt','LegalAdhocTask/ConsumerCourtAdhocdata/SCDRC/**/*.txt', 'LegalAdhocTask/SC-HCAdhocData/DelhiHC/**/*.txt','LegalAdhocTask/SC-HCAdhocData/JharkhandHC/**/*.txt', 'LegalAdhocTask/SC-HCAdhocData/JodhpurHC/**/*.txt' ,'LegalAdhocTask/SC-HCAdhocData/KolkataHC/**/*.txt', 'LegalAdhocTask/SC-HCAdhocData/SupremeCourt/**/*.txt']\n",
    "for glob_filenames in x:\n",
    "    glob_filenames = os.path.normpath(glob_filenames)\n",
    "    for filename in sorted(glob2.glob(glob_filenames)):\n",
    "        filenames.append(os.path.basename(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_stop = set(get_stop_words('en'))\n",
    "\n",
    "# \"yield\" for each file return token list  i.e list of lists\n",
    "def files_to_tokens(glob_filenames):\n",
    "    glob_filenames = os.path.normpath(glob_filenames)\n",
    "    for filename in sorted(glob2.glob(glob_filenames)):\n",
    "        f = open(filename)\n",
    "        #print filename\n",
    "        # read the whole file as lowercase string\n",
    "        string = (f.read()).lower()\n",
    "        try:\n",
    "            temp = word_tokenize(string)\n",
    "        except:\n",
    "            string = string.decode(\"latin-1\")\n",
    "            temp = word_tokenize(string)\n",
    "        \n",
    "        tokens = []\n",
    "        # tokenize that string\n",
    "        for word in temp:\n",
    "            w =  only_alphabet(word).lower()\n",
    "            if w not in en_stop:\n",
    "                if w:\n",
    "                    tokens.append(w)\n",
    "        tokens = tag_and_lem(tokens)\n",
    "        yield tokens\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "# yields token list for files specific to courts; needed for creating dictionaries\n",
    "class texts:\n",
    "    def DCDRC(self):\n",
    "        return files_to_tokens('LegalAdhocTask/ConsumerCourtAdhocdata/DCDRC/**/*.txt')\n",
    "    def NCDRC(self):\n",
    "        return files_to_tokens('LegalAdhocTask/ConsumerCourtAdhocdata/NCDRC/**/*.txt')\n",
    "    def SCDRC(self):\n",
    "        return files_to_tokens('LegalAdhocTask/ConsumerCourtAdhocdata/SCDRC/**/*.txt')\n",
    "    def DelhiHC(self):\n",
    "        return files_to_tokens('LegalAdhocTask/SC-HCAdhocData/DelhiHC/**/*.txt')\n",
    "    def JharkhandHC(self):\n",
    "        return files_to_tokens('LegalAdhocTask/SC-HCAdhocData/JharkhandHC/**/*.txt')\n",
    "    def JodhpurHC(self):\n",
    "        return files_to_tokens('LegalAdhocTask/SC-HCAdhocData/JodhpurHC/**/*.txt')\n",
    "    def KolkataHC(self):\n",
    "        return files_to_tokens('LegalAdhocTask/SC-HCAdhocData/KolkataHC/**/*.txt')\n",
    "    def SupremeCourt(self):\n",
    "        return files_to_tokens('LegalAdhocTask/SC-HCAdhocData/SupremeCourt/**/*.txt')\n",
    "    def everything(self):\n",
    "        return chain(self.DCDRC(), self.NCDRC(), self.SCDRC(), self.DelhiHC(),\n",
    "                     self.JharkhandHC(), self.JodhpurHC(), self.KolkataHC(), self.SupremeCourt())\n",
    "\n",
    "# yields bow for each file - tuples id,fq ; needed to train models   \n",
    "class my_corpus:    \n",
    "    def DCDRC(self):\n",
    "        for text in files_to_tokens('LegalAdhocTask/ConsumerCourtAdhocdata/DCDRC/*.txt'):\n",
    "            yield dictionary.doc2bow(text)\n",
    "    def NCDRC(self):\n",
    "        for text in files_to_tokens('LegalAdhocTask/ConsumerCourtAdhocdata/NCDRC/**/*.txt'):\n",
    "            yield dictionary.doc2bow(text)            \n",
    "    def SCDRC(self):\n",
    "        for text in files_to_tokens('LegalAdhocTask/ConsumerCourtAdhocdata/SCDRC/**/*.txt'):\n",
    "            yield dictionary.doc2bow(text)\n",
    "    def DelhiHC(self):\n",
    "        for text in files_to_tokens('LegalAdhocTask/SC-HCAdhocData/DelhiHC/**/*.txt'):\n",
    "            yield dictionary.doc2bow(text)\n",
    "    def JharkhandHC(self):\n",
    "        for text in files_to_tokens('LegalAdhocTask/SC-HCAdhocData/JharkhandHC/**/*.txt'):\n",
    "            yield dictionary.doc2bow(text)\n",
    "    def JodhpurHC(self):\n",
    "        for text in  files_to_tokens('LegalAdhocTask/SC-HCAdhocData/JodhpurHC/**/*.txt'):\n",
    "            yield dictionary.doc2bow(text)\n",
    "    def KolkataHC(self):\n",
    "        for text in  files_to_tokens('LegalAdhocTask/SC-HCAdhocData/KolkataHC/**/*.txt'):\n",
    "            yield dictionary.doc2bow(text)\n",
    "    def SupremeCourt(self):\n",
    "        for text in  files_to_tokens('LegalAdhocTask/SC-HCAdhocData/SupremeCourt/**/*.txt'):\n",
    "            yield dictionary.doc2bow(text)\n",
    "    def everything(self):\n",
    "        return chain(self.DCDRC(), self.NCDRC(), self.SCDRC(), self.DelhiHC(),\n",
    "                     self.JharkhandHC(), self.JodhpurHC(), self.KolkataHC(), self.SupremeCourt())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-03 22:00:08,067 : INFO : loading Dictionary object from dict/lem10\n",
      "2018-05-03 22:00:08,117 : INFO : loaded dict/lem10\n"
     ]
    }
   ],
   "source": [
    "#################################### laod the dictinary\n",
    "dictionary = corpora.Dictionary.load('dict/lem10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-03 22:00:08,289 : INFO : loaded corpus index from corpus/bow_lem10.mm.index\n",
      "2018-05-03 22:00:08,289 : INFO : initializing cython corpus reader from corpus/bow_lem10.mm\n",
      "2018-05-03 22:00:08,290 : INFO : accepted corpus with 351985 documents, 169716 features, 99651009 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "######################################## load BOW\n",
    "corpus = corpora.MmCorpus('corpus/bow_lem10.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = texts()\n",
    "count = 0\n",
    "for x in c.everything():\n",
    "    x = [ i for i in x if i in dictionary.token2id]\n",
    "    with open(os.path.normpath('Token_corpus2/' + str(count)), 'wb') as fp:\n",
    "        pickle.dump(x, fp)\n",
    "    count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_corpus(i):\n",
    "    with open (os.path.normpath('Token_corpus2/' + str(i)), 'rb') as fp:\n",
    "            itemlist = pickle.load(fp)\n",
    "            return itemlist   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class iter_token_corpus:\n",
    "    def __iter__(self):\n",
    "        for i in xrange(0, 351985):\n",
    "            with open (os.path.normpath('Token_corpus2/' + str(i)), 'rb') as fp:\n",
    "                itemlist = pickle.load(fp)\n",
    "                yield itemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = gensim.models.Word2Vec(iter_token_corpus(), sg = 1, hs=1, size=300, iter = 20, min_count=0, sample=.00001, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('py_models/W2V_SG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('py_models/W2V_SG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x.doesnt_match(words)\n",
    "\n",
    "# #     Which word from the given list doesn’t go with the others?\n",
    "# #     Parameters:\twords – List of words\n",
    "# #     Returns:\tThe word further away from the mean of all words.\n",
    "# #     Return type:\tstr\n",
    "\n",
    "# x.index2word\n",
    "# ### list of words in the sorted order of their frequency \n",
    "\n",
    "# y = x.vocab['parti']\n",
    "# y.count\n",
    "# # find freq. of any word\n",
    "\n",
    "\n",
    "# x.most_similar_cosmul(positive=None, negative=None, topn=10)\n",
    "# # Find the top-N most similar words, using the multiplicative combination objective proposed by \n",
    "# # Omer Levy and Yoav Goldberg.Positive words still contribute positively towards the similarity, negative words \n",
    "# # negatively, but with less susceptibility to one large distance dominating the calculation.\n",
    "\n",
    "# x.most_similar_to_given(entity1, entities_list)\n",
    "# #    Return the entity from entities_list most similar to entity1.\n",
    "\n",
    "# x.n_similarity(ws1, ws2)\n",
    "# #Compute cosine similarity between two sets of words\n",
    "\n",
    "\n",
    "# x.similar_by_vector(x['fit'], topn=10, restrict_vocab=None)\n",
    "# # closest vectors\n",
    "# # if topn is False, similar_by_vector returns the vector of similarity scores.\n",
    "\n",
    "# x.similar_by_word(word, topn=10, restrict_vocab=None)\n",
    "# #  Find the top-N most similar words.\n",
    "\n",
    "# x.similarity(w1, w2)\n",
    "# #Compute cosine similarity between two words.\n",
    "\n",
    "# x.wmdistance(doc1, doc2)\n",
    "# # word movers distance\n",
    "\n",
    "# y = x.vocab['parti']\n",
    "# y.count\n",
    "# #freq in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import math\n",
    "from six import iteritems\n",
    "from six.moves import xrange\n",
    "idf = {}\n",
    "for word, freq in dictionary.dfs.iteritems():\n",
    "    idf[dictionary.id2token[word]] = math.log(dictionary.num_docs) - math.log(freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the query truth in dictionary\n",
    "query_truth = {}\n",
    "for i in range(1,11):\n",
    "    query_truth[str(i)]=[]\n",
    "    \n",
    "    \n",
    "f = open('LegalAdhocTask/Consumer.qrels')\n",
    "lines = [line.rstrip('\\n').split(\"\\t\") for line in f]\n",
    "for line in lines:\n",
    "    del line[1]\n",
    "    query_truth[line[0]].append(line[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = model.wv\n",
    "def vec(document):\n",
    "    return np.add.reduce([idf[i]*w2v[i] for i in document if i in dictionary.token2id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_vec = []\n",
    "for x in iter_token_corpus():\n",
    "    x = vec(x)\n",
    "    doc_vec.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def get_scores(query):\n",
    "    scores = []\n",
    "    i = 0\n",
    "    query = vec(query)\n",
    "    for x in doc_vec:\n",
    "        if isinstance(x, np.ndarray):\n",
    "            score = 1 - cosine(x, query)\n",
    "        else:\n",
    "            score = -1000\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-29 17:57:43,118 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.0\n",
      "2018-04-29 17:57:43,119 : INFO : loading index from py_models/tfidf_lem10.index.0.index.npy with mmap=r\n",
      "2018-04-29 17:57:43,120 : INFO : loaded py_models/tfidf_lem10.index.0\n",
      "2018-04-29 17:57:43,157 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.1\n",
      "2018-04-29 17:57:43,203 : INFO : loaded py_models/tfidf_lem10.index.1\n",
      "2018-04-29 17:57:43,237 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.2\n",
      "2018-04-29 17:57:43,238 : INFO : loading index from py_models/tfidf_lem10.index.2.index.npy with mmap=r\n",
      "2018-04-29 17:57:43,240 : INFO : loaded py_models/tfidf_lem10.index.2\n",
      "2018-04-29 17:57:43,282 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.3\n",
      "2018-04-29 17:57:43,338 : INFO : loaded py_models/tfidf_lem10.index.3\n",
      "2018-04-29 17:57:43,372 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.4\n",
      "2018-04-29 17:57:43,418 : INFO : loaded py_models/tfidf_lem10.index.4\n",
      "2018-04-29 17:57:43,446 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.5\n",
      "2018-04-29 17:57:43,447 : INFO : loading index from py_models/tfidf_lem10.index.5.index.npy with mmap=r\n",
      "2018-04-29 17:57:43,448 : INFO : loaded py_models/tfidf_lem10.index.5\n",
      "2018-04-29 17:57:43,488 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.6\n",
      "2018-04-29 17:57:43,545 : INFO : loaded py_models/tfidf_lem10.index.6\n",
      "2018-04-29 17:57:43,578 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.7\n",
      "2018-04-29 17:57:43,589 : INFO : loaded py_models/tfidf_lem10.index.7\n",
      "2018-04-29 17:57:43,599 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.8\n",
      "2018-04-29 17:57:43,616 : INFO : loaded py_models/tfidf_lem10.index.8\n",
      "2018-04-29 17:57:43,629 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.9\n",
      "2018-04-29 17:57:43,676 : INFO : loaded py_models/tfidf_lem10.index.9\n",
      "2018-04-29 17:57:43,704 : INFO : loading SparseMatrixSimilarity object from py_models/tfidf_lem10.index.10\n",
      "2018-04-29 17:57:43,704 : INFO : loading index from py_models/tfidf_lem10.index.10.index.npy with mmap=r\n",
      "2018-04-29 17:57:43,706 : INFO : loaded py_models/tfidf_lem10.index.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.72 s, sys: 240 ms, total: 6.96 s\n",
      "Wall time: 7.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = copy.deepcopy(query_truth)\n",
    "\n",
    "sim_list = [0]\n",
    "rank_list = [0]\n",
    "queries = [0]\n",
    "for i,query in enumerate(files_to_tokens('LegalAdhocTask/q*.txt')):\n",
    "    queries.append(query)\n",
    "    sims = get_scores(query)\n",
    "    sim_list.append(sims)\n",
    "    # rank of every document wrt similarity\n",
    "    ranks = rankdata(sims, method='ordinal')\n",
    "    ranks= len(ranks)+1 - ranks \n",
    "    rank_list.append(ranks)\n",
    "    \n",
    "    # update the query truth tuples with similarity score and the ranks\n",
    "    for x in results[str(i+1)]:\n",
    "        x.append(sims[filenames.index(x[0]+'.txt')])\n",
    "        x.append(ranks[filenames.index(x[0]+'.txt')])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [['ConsumerCourt_DCDRC_100385', '1', 0.16185194, 205],\n",
       "  ['ConsumerCourt_DCDRC_106530', '0', 0.066299856, 2049],\n",
       "  ['ConsumerCourt_DCDRC_107608', '1', 0.08884313, 1231],\n",
       "  ['ConsumerCourt_DCDRC_114291', '1', 0.12928788, 532],\n",
       "  ['ConsumerCourt_DCDRC_114382', '1', 0.10607624, 893],\n",
       "  ['ConsumerCourt_DCDRC_118185', '1', 0.09642149, 1088],\n",
       "  ['ConsumerCourt_DCDRC_130318', '0', 0.1199432, 653],\n",
       "  ['ConsumerCourt_DCDRC_130570', '1', 0.27709824, 7],\n",
       "  ['ConsumerCourt_DCDRC_131146', '1', 0.06343228, 2197],\n",
       "  ['ConsumerCourt_DCDRC_131717', '1', 0.08180869, 1438],\n",
       "  ['ConsumerCourt_DCDRC_131741', '1', 0.07304419, 1746],\n",
       "  ['ConsumerCourt_DCDRC_131818', '1', 0.09741112, 1068],\n",
       "  ['ConsumerCourt_DCDRC_131950', '0', 0.05442484, 2824],\n",
       "  ['ConsumerCourt_DCDRC_131972', '0', 0.08816901, 1251],\n",
       "  ['ConsumerCourt_DCDRC_132932', '0', 0.06848099, 1925],\n",
       "  ['ConsumerCourt_DCDRC_133592', '1', 0.1699525, 155],\n",
       "  ['ConsumerCourt_DCDRC_134386', '0', 0.33104795, 1],\n",
       "  ['ConsumerCourt_DCDRC_135474', '1', 0.061556537, 2329],\n",
       "  ['ConsumerCourt_DCDRC_139024', '0', 0.18092416, 105],\n",
       "  ['ConsumerCourt_DCDRC_139205', '0', 0.2791601, 5],\n",
       "  ['ConsumerCourt_DCDRC_140039', '1', 0.25601915, 14],\n",
       "  ['ConsumerCourt_DCDRC_145708', '0', 0.23000303, 24],\n",
       "  ['ConsumerCourt_DCDRC_187214', '1', 0.055584818, 2722],\n",
       "  ['ConsumerCourt_DCDRC_207784', '1', 0.03674183, 5278],\n",
       "  ['ConsumerCourt_DCDRC_217344', '1', 0.18479005, 89],\n",
       "  ['ConsumerCourt_DCDRC_217471', '1', 0.13771655, 417],\n",
       "  ['ConsumerCourt_DCDRC_222797', '0', 0.142882, 365],\n",
       "  ['ConsumerCourt_DCDRC_222844', '1', 0.14383788, 355],\n",
       "  ['ConsumerCourt_DCDRC_224228', '0', 0.18566678, 85],\n",
       "  ['ConsumerCourt_DCDRC_224833', '0', 0.11406111, 740],\n",
       "  ['ConsumerCourt_DCDRC_226072', '1', 0.2247357, 26],\n",
       "  ['ConsumerCourt_DCDRC_38498', '0', 0.25151008, 17],\n",
       "  ['ConsumerCourt_DCDRC_39186', '1', 0.15644196, 237],\n",
       "  ['ConsumerCourt_DCDRC_41317', '1', 0.22002132, 31],\n",
       "  ['ConsumerCourt_DCDRC_41588', '1', 0.18472102, 90],\n",
       "  ['ConsumerCourt_DCDRC_42118', '1', 0.13853158, 408],\n",
       "  ['ConsumerCourt_DCDRC_42618', '1', 0.13754933, 420],\n",
       "  ['ConsumerCourt_DCDRC_42649', '1', 0.31588802, 2],\n",
       "  ['ConsumerCourt_DCDRC_44200', '1', 0.12468188, 585],\n",
       "  ['ConsumerCourt_DCDRC_46368', '1', 0.118411794, 672],\n",
       "  ['ConsumerCourt_DCDRC_46519', '1', 0.15088913, 294],\n",
       "  ['ConsumerCourt_DCDRC_46543', '1', 0.103566095, 944],\n",
       "  ['ConsumerCourt_DCDRC_53138', '1', 0.1321914, 487],\n",
       "  ['ConsumerCourt_DCDRC_55517', '1', 0.20306638, 53],\n",
       "  ['ConsumerCourt_DCDRC_55612', '1', 0.112715356, 764],\n",
       "  ['ConsumerCourt_DCDRC_55678', '1', 0.17311196, 143],\n",
       "  ['ConsumerCourt_DCDRC_55899', '1', 0.18001184, 111],\n",
       "  ['ConsumerCourt_DCDRC_57484', '0', 0.2532293, 15],\n",
       "  ['ConsumerCourt_DCDRC_74868', '1', 0.1236761, 601],\n",
       "  ['ConsumerCourt_DCDRC_80057', '1', 0.26865602, 10],\n",
       "  ['ConsumerCourt_DCDRC_83596', '0', 0.15309563, 270],\n",
       "  ['ConsumerCourt_DCDRC_83779', '0', 0.14001663, 396],\n",
       "  ['ConsumerCourt_DCDRC_96667', '1', 0.2404279, 20],\n",
       "  ['ConsumerCourt_DCDRC_98733', '1', 0.25267765, 16],\n",
       "  ['ConsumerCourt_SCDRC_52678', '0', 0.13144559, 498],\n",
       "  ['DelhiHC_2011_4267', '0', 0.10414553, 934],\n",
       "  ['KolkataHCOriginalSite_2012_36', '0', 0.033456348, 6232]],\n",
       " '10': [['ConsumerCourt_DCDRC_220958', '0', 0.09642182, 1011],\n",
       "  ['ConsumerCourt_DCDRC_222509', '0', 0.31595787, 4],\n",
       "  ['ConsumerCourt_DCDRC_223570', '0', 0.30834275, 5],\n",
       "  ['ConsumerCourt_DCDRC_227314', '0', 0.12794511, 471],\n",
       "  ['ConsumerCourt_DCDRC_228688', '1', 0.28662106, 8],\n",
       "  ['ConsumerCourt_DCDRC_235883', '0', 0.26839116, 12],\n",
       "  ['ConsumerCourt_DCDRC_38192', '0', 0.41595137, 2],\n",
       "  ['ConsumerCourt_DCDRC_41485', '0', 0.26378343, 16],\n",
       "  ['ConsumerCourt_DCDRC_41489', '0', 0.26378343, 15],\n",
       "  ['ConsumerCourt_DCDRC_41520', '0', 0.2668716, 14],\n",
       "  ['ConsumerCourt_SCDRC_44836', '0', 0.19624285, 74],\n",
       "  ['ConsumerCourt_SCDRC_56350', '0', 0.27424642, 11],\n",
       "  ['ConsumerCourt_SCDRC_65898', '0', 0.25429, 20],\n",
       "  ['ConsumerCourt_SCDRC_68718', '0', 0.25706196, 19],\n",
       "  ['ConsumerCourt_SCDRC_69937', '1', 0.5464984, 1],\n",
       "  ['ConsumerCourt_SCDRC_70632', '0', 0.105837665, 790],\n",
       "  ['DelhiHC_2008_2771', '0', 0.17349324, 140],\n",
       "  ['DelhiHC_2008_2772', '0', 0.17349324, 139]],\n",
       " '2': [['ConsumerCourt_DCDRC_103241', '0', 0.05116509, 1934],\n",
       "  ['ConsumerCourt_DCDRC_107786', '1', 0.29168144, 184],\n",
       "  ['ConsumerCourt_DCDRC_114305', '1', 0.387323, 35],\n",
       "  ['ConsumerCourt_DCDRC_120930', '1', 0.3830618, 41],\n",
       "  ['ConsumerCourt_DCDRC_123490', '1', 0.33731648, 100],\n",
       "  ['ConsumerCourt_DCDRC_125352', '1', 0.43188536, 6],\n",
       "  ['ConsumerCourt_DCDRC_127791', '0', 0.06714895, 1299],\n",
       "  ['ConsumerCourt_DCDRC_130071', '0', 0.08628778, 964],\n",
       "  ['ConsumerCourt_DCDRC_130920', '1', 0.2891528, 188],\n",
       "  ['ConsumerCourt_DCDRC_131972', '0', 0.059945945, 1496],\n",
       "  ['ConsumerCourt_DCDRC_133106', '1', 0.3951745, 31],\n",
       "  ['ConsumerCourt_DCDRC_133260', '0', 0.37977216, 43],\n",
       "  ['ConsumerCourt_DCDRC_143284', '1', 0.30487663, 149],\n",
       "  ['ConsumerCourt_DCDRC_143334', '0', 0.40973663, 18],\n",
       "  ['ConsumerCourt_DCDRC_144440', '0', 0.17394999, 476],\n",
       "  ['ConsumerCourt_DCDRC_202900', '0', 0.018241521, 36529],\n",
       "  ['ConsumerCourt_DCDRC_202903', '0', 0.01594568, 52683],\n",
       "  ['ConsumerCourt_DCDRC_207376', '1', 0.058631595, 1554],\n",
       "  ['ConsumerCourt_DCDRC_212601', '0', 0.28668, 197],\n",
       "  ['ConsumerCourt_DCDRC_212692', '1', 0.4339986, 5],\n",
       "  ['ConsumerCourt_DCDRC_214518', '1', 0.36593345, 58],\n",
       "  ['ConsumerCourt_DCDRC_226924', '0', 0.25521833, 263],\n",
       "  ['ConsumerCourt_DCDRC_227866', '1', 0.42666116, 10],\n",
       "  ['ConsumerCourt_DCDRC_228749', '1', 0.3500358, 84],\n",
       "  ['ConsumerCourt_DCDRC_229221', '0', 0.35415915, 78],\n",
       "  ['ConsumerCourt_DCDRC_230361', '1', 0.42097464, 12],\n",
       "  ['ConsumerCourt_DCDRC_41190', '0', 0.054519515, 1734],\n",
       "  ['ConsumerCourt_DCDRC_50671', '1', 0.081553325, 1017],\n",
       "  ['ConsumerCourt_DCDRC_52620', '1', 0.06963155, 1256],\n",
       "  ['ConsumerCourt_DCDRC_53093', '1', 0.3672748, 55],\n",
       "  ['ConsumerCourt_DCDRC_53138', '0', 0.040126923, 3397],\n",
       "  ['ConsumerCourt_DCDRC_53153', '1', 0.10388352, 794],\n",
       "  ['ConsumerCourt_DCDRC_53432', '0', 0.05672295, 1631],\n",
       "  ['ConsumerCourt_DCDRC_53875', '0', 0.06323096, 1391],\n",
       "  ['ConsumerCourt_DCDRC_53881', '0', 0.06323096, 1390],\n",
       "  ['ConsumerCourt_DCDRC_56471', '1', 0.19100128, 420],\n",
       "  ['ConsumerCourt_DCDRC_56761', '0', 0.04129476, 3144],\n",
       "  ['ConsumerCourt_DCDRC_57453', '0', 0.3275077, 118],\n",
       "  ['ConsumerCourt_DCDRC_57583', '0', 0.038953524, 3671],\n",
       "  ['ConsumerCourt_DCDRC_62986', '0', 0.34571543, 91],\n",
       "  ['ConsumerCourt_DCDRC_63724', '0', 0.28970197, 187],\n",
       "  ['ConsumerCourt_DCDRC_68765', '0', 0.2720819, 222],\n",
       "  ['ConsumerCourt_DCDRC_68808', '0', 0.18697113, 432],\n",
       "  ['ConsumerCourt_DCDRC_69863', '0', 0.2272508, 335],\n",
       "  ['ConsumerCourt_DCDRC_74887', '0', 0.30115408, 165],\n",
       "  ['ConsumerCourt_DCDRC_75562', '0', 0.37434208, 50],\n",
       "  ['ConsumerCourt_DCDRC_76114', '0', 0.36304817, 64],\n",
       "  ['ConsumerCourt_DCDRC_76186', '0', 0.19231616, 417],\n",
       "  ['ConsumerCourt_DCDRC_76270', '0', 0.24704473, 283],\n",
       "  ['ConsumerCourt_DCDRC_77085', '1', 0.33069566, 113],\n",
       "  ['ConsumerCourt_DCDRC_77280', '0', 0.042803638, 2897],\n",
       "  ['ConsumerCourt_DCDRC_77935', '1', 0.38617077, 37],\n",
       "  ['ConsumerCourt_DCDRC_87186', '0', 0.29542562, 178],\n",
       "  ['ConsumerCourt_DCDRC_91864', '1', 0.40101635, 25],\n",
       "  ['ConsumerCourt_DCDRC_96244', '1', 0.43737224, 4],\n",
       "  ['ConsumerCourt_NCDRC_1317', '0', 0.35751197, 73],\n",
       "  ['ConsumerCourt_SCDRC_49685', '0', 0.32498217, 123],\n",
       "  ['ConsumerCourt_SCDRC_60064', '1', 0.4747356, 1],\n",
       "  ['ConsumerCourt_SCDRC_62062', '1', 0.38968801, 33]],\n",
       " '3': [['ConsumerCourt_DCDRC_103355', '0', 0.105795614, 383],\n",
       "  ['ConsumerCourt_DCDRC_129293', '1', 0.3341779, 4],\n",
       "  ['ConsumerCourt_DCDRC_133013', '1', 0.15773119, 93],\n",
       "  ['ConsumerCourt_DCDRC_133017', '0', 0.22281633, 26],\n",
       "  ['ConsumerCourt_DCDRC_137661', '0', 0.10284864, 435],\n",
       "  ['ConsumerCourt_DCDRC_153064', '0', 0.032149572, 7621],\n",
       "  ['ConsumerCourt_DCDRC_187619', '1', 0.28784367, 9],\n",
       "  ['ConsumerCourt_DCDRC_200840', '0', 0.14488558, 136],\n",
       "  ['ConsumerCourt_DCDRC_222260', '1', 0.21672036, 28],\n",
       "  ['ConsumerCourt_DCDRC_222772', '1', 0.22915016, 22],\n",
       "  ['ConsumerCourt_DCDRC_223618', '1', 0.20526212, 36],\n",
       "  ['ConsumerCourt_DCDRC_228476', '0', 0.10687368, 371],\n",
       "  ['ConsumerCourt_DCDRC_228963', '1', 0.23827143, 20],\n",
       "  ['ConsumerCourt_DCDRC_230634', '1', 0.25547072, 15],\n",
       "  ['ConsumerCourt_DCDRC_235824', '0', 0.3343033, 3],\n",
       "  ['ConsumerCourt_DCDRC_45666', '0', 0.081762105, 863],\n",
       "  ['ConsumerCourt_DCDRC_47493', '1', 0.15302804, 104],\n",
       "  ['ConsumerCourt_DCDRC_52566', '0', 0.16868195, 70],\n",
       "  ['ConsumerCourt_DCDRC_73184', '0', 0.15768361, 94],\n",
       "  ['ConsumerCourt_DCDRC_73185', '0', 0.16764536, 72],\n",
       "  ['ConsumerCourt_NCDRC_2861', '1', 0.124772586, 214],\n",
       "  ['ConsumerCourt_NCDRC_2902', '0', 0.057073794, 2263],\n",
       "  ['ConsumerCourt_NCDRC_2979', '0', 0.102176756, 446],\n",
       "  ['ConsumerCourt_NCDRC_632', '0', 0.102791876, 437],\n",
       "  ['ConsumerCourt_NCDRC_637', '0', 0.10263641, 441],\n",
       "  ['ConsumerCourt_SCDRC_2052', '0', 0.28015804, 12],\n",
       "  ['ConsumerCourt_SCDRC_22704', '0', 0.09891514, 499],\n",
       "  ['ConsumerCourt_SCDRC_29484', '0', 0.16089258, 89],\n",
       "  ['ConsumerCourt_SCDRC_29552', '0', 0.06217157, 1855],\n",
       "  ['ConsumerCourt_SCDRC_30176', '0', 0.17636095, 60],\n",
       "  ['ConsumerCourt_SCDRC_48394', '0', 0.11484798, 295],\n",
       "  ['ConsumerCourt_SCDRC_63569', '0', 0.098075025, 505],\n",
       "  ['ConsumerCourt_SCDRC_63609', '0', 0.17358449, 64],\n",
       "  ['ConsumerCourt_SCDRC_65919', '0', 0.23171596, 21],\n",
       "  ['ConsumerCourt_SCDRC_66200', '0', 0.14707991, 128],\n",
       "  ['ConsumerCourt_SCDRC_69801', '0', 0.09011969, 652],\n",
       "  ['ConsumerCourt_SCDRC_814', '0', 0.078205794, 986],\n",
       "  ['DelhiHC_2012_388', '0', 0.043359995, 4094]],\n",
       " '4': [['ConsumerCourt_DCDRC_106570', '0', 0.24891731, 188],\n",
       "  ['ConsumerCourt_DCDRC_116129', '1', 0.25496536, 146],\n",
       "  ['ConsumerCourt_DCDRC_128836', '0', 0.1828827, 839],\n",
       "  ['ConsumerCourt_DCDRC_130725', '1', 0.2194786, 411],\n",
       "  ['ConsumerCourt_DCDRC_133137', '0', 0.25046524, 173],\n",
       "  ['ConsumerCourt_DCDRC_173376', '0', 0.025167977, 44608],\n",
       "  ['ConsumerCourt_DCDRC_174292', '0', 0.17596701, 945],\n",
       "  ['ConsumerCourt_DCDRC_174300', '1', 0.15809764, 1312],\n",
       "  ['ConsumerCourt_DCDRC_202903', '0', 0.010021221, 149658],\n",
       "  ['ConsumerCourt_DCDRC_205816', '1', 0.19839443, 610],\n",
       "  ['ConsumerCourt_DCDRC_207155', '0', 0.088249676, 6144],\n",
       "  ['ConsumerCourt_DCDRC_207197', '0', 0.2201435, 404],\n",
       "  ['ConsumerCourt_DCDRC_212467', '1', 0.26130852, 118],\n",
       "  ['ConsumerCourt_DCDRC_213156', '0', 0.2203923, 401],\n",
       "  ['ConsumerCourt_DCDRC_213473', '0', 0.23071097, 320],\n",
       "  ['ConsumerCourt_DCDRC_213784', '0', 0.26569358, 96],\n",
       "  ['ConsumerCourt_DCDRC_214475', '0', 0.23070188, 321],\n",
       "  ['ConsumerCourt_DCDRC_218582', '0', 0.16745216, 1111],\n",
       "  ['ConsumerCourt_DCDRC_221177', '0', 0.18151459, 862],\n",
       "  ['ConsumerCourt_DCDRC_221424', '0', 0.23873559, 275],\n",
       "  ['ConsumerCourt_DCDRC_223275', '0', 0.22893964, 334],\n",
       "  ['ConsumerCourt_DCDRC_226909', '0', 0.067029245, 10314],\n",
       "  ['ConsumerCourt_DCDRC_227099', '0', 0.17884895, 901],\n",
       "  ['ConsumerCourt_DCDRC_229902', '0', 0.14634013, 1654],\n",
       "  ['ConsumerCourt_DCDRC_47636', '0', 0.14041694, 1846],\n",
       "  ['ConsumerCourt_DCDRC_49131', '0', 0.3270531, 6],\n",
       "  ['ConsumerCourt_DCDRC_51881', '0', 0.28924116, 30],\n",
       "  ['ConsumerCourt_DCDRC_52357', '0', 0.31467402, 11],\n",
       "  ['ConsumerCourt_DCDRC_53202', '0', 0.29179263, 26],\n",
       "  ['ConsumerCourt_DCDRC_53580', '1', 0.28916618, 31],\n",
       "  ['ConsumerCourt_DCDRC_54056', '1', 0.2478979, 201],\n",
       "  ['ConsumerCourt_DCDRC_70122', '0', 0.26983234, 82],\n",
       "  ['ConsumerCourt_DCDRC_73309', '0', 0.26981872, 83],\n",
       "  ['ConsumerCourt_NCDRC_2154', '0', 0.060251523, 12173],\n",
       "  ['ConsumerCourt_NCDRC_3506', '0', 0.085250735, 6644],\n",
       "  ['ConsumerCourt_SCDRC_1143', '1', 0.27000868, 80],\n",
       "  ['ConsumerCourt_SCDRC_1288', '1', 0.31690243, 10],\n",
       "  ['ConsumerCourt_SCDRC_22830', '0', 0.16168913, 1227],\n",
       "  ['ConsumerCourt_SCDRC_37679', '1', 0.25058728, 171],\n",
       "  ['ConsumerCourt_SCDRC_471', '0', 0.06492559, 10853],\n",
       "  ['ConsumerCourt_SCDRC_49973', '1', 0.25199616, 165],\n",
       "  ['ConsumerCourt_SCDRC_5406', '0', 0.12062388, 2879],\n",
       "  ['ConsumerCourt_SCDRC_7046', '1', 0.33807057, 3],\n",
       "  ['DelhiHC_2012_3856', '0', 0.09199201, 5625],\n",
       "  ['SupremeCourt_2009_1421', '0', 0.18089704, 872]],\n",
       " '5': [['ConsumerCourt_DCDRC_124651', '0', 0.1380009, 1710],\n",
       "  ['ConsumerCourt_DCDRC_138545', '0', 0.21531987, 371],\n",
       "  ['ConsumerCourt_DCDRC_139183', '0', 0.29358536, 31],\n",
       "  ['ConsumerCourt_DCDRC_141380', '0', 0.10652409, 2868],\n",
       "  ['ConsumerCourt_DCDRC_148691', '1', 0.31213897, 10],\n",
       "  ['ConsumerCourt_DCDRC_202903', '0', 0.0063688266, 187527],\n",
       "  ['ConsumerCourt_DCDRC_208296', '0', 0.17331758, 921],\n",
       "  ['ConsumerCourt_DCDRC_223817', '0', 0.19273905, 602],\n",
       "  ['ConsumerCourt_DCDRC_226994', '0', 0.045381997, 9427],\n",
       "  ['ConsumerCourt_DCDRC_229911', '1', 0.22368848, 299],\n",
       "  ['ConsumerCourt_DCDRC_41155', '1', 0.25733244, 118],\n",
       "  ['ConsumerCourt_DCDRC_41262', '0', 0.2505672, 142],\n",
       "  ['ConsumerCourt_DCDRC_41428', '0', 0.22484241, 291],\n",
       "  ['ConsumerCourt_DCDRC_42411', '0', 0.13904752, 1684],\n",
       "  ['ConsumerCourt_DCDRC_46404', '0', 0.26110348, 103],\n",
       "  ['ConsumerCourt_DCDRC_53679', '1', 0.15456897, 1276],\n",
       "  ['ConsumerCourt_DCDRC_57315', '1', 0.23405942, 237],\n",
       "  ['ConsumerCourt_DCDRC_57465', '0', 0.1258907, 2075],\n",
       "  ['ConsumerCourt_DCDRC_57488', '0', 0.23475426, 231],\n",
       "  ['ConsumerCourt_DCDRC_57914', '1', 0.2681473, 83],\n",
       "  ['ConsumerCourt_DCDRC_66294', '0', 0.22213382, 307],\n",
       "  ['ConsumerCourt_DCDRC_96799', '0', 0.2952276, 29],\n",
       "  ['ConsumerCourt_NCDRC_1337', '1', 0.30042246, 24],\n",
       "  ['ConsumerCourt_NCDRC_1338', '0', 0.30042246, 23],\n",
       "  ['ConsumerCourt_NCDRC_2983', '1', 0.26576623, 88],\n",
       "  ['ConsumerCourt_SCDRC_28656', '0', 0.23637797, 223],\n",
       "  ['ConsumerCourt_SCDRC_33517', '1', 0.33069202, 3],\n",
       "  ['ConsumerCourt_SCDRC_5122', '0', 0.19560242, 572],\n",
       "  ['ConsumerCourt_SCDRC_71374', '1', 0.19175802, 620]],\n",
       " '6': [['ConsumerCourt_DCDRC_103021', '1', 0.36711788, 1],\n",
       "  ['ConsumerCourt_DCDRC_119836', '1', 0.08526744, 750],\n",
       "  ['ConsumerCourt_DCDRC_125237', '1', 0.03284732, 4500],\n",
       "  ['ConsumerCourt_DCDRC_126276', '0', 0.045523252, 2496],\n",
       "  ['ConsumerCourt_DCDRC_131266', '1', 0.1562739, 169],\n",
       "  ['ConsumerCourt_DCDRC_133353', '1', 0.09529114, 575],\n",
       "  ['ConsumerCourt_DCDRC_133354', '0', 0.08403072, 773],\n",
       "  ['ConsumerCourt_DCDRC_134804', '0', 0.08163838, 824],\n",
       "  ['ConsumerCourt_DCDRC_138617', '1', 0.12635577, 309],\n",
       "  ['ConsumerCourt_DCDRC_143983', '0', 0.025932606, 7435],\n",
       "  ['ConsumerCourt_DCDRC_207387', '1', 0.11922688, 356],\n",
       "  ['ConsumerCourt_DCDRC_220958', '1', 0.14947952, 196],\n",
       "  ['ConsumerCourt_DCDRC_223570', '1', 0.09919912, 523],\n",
       "  ['ConsumerCourt_DCDRC_223783', '0', 0.110854834, 416],\n",
       "  ['ConsumerCourt_DCDRC_38192', '1', 0.18152007, 108],\n",
       "  ['ConsumerCourt_DCDRC_41485', '0', 0.11963005, 354],\n",
       "  ['ConsumerCourt_DCDRC_41489', '0', 0.11963005, 353],\n",
       "  ['ConsumerCourt_DCDRC_41520', '1', 0.12564632, 314],\n",
       "  ['ConsumerCourt_DCDRC_45421', '0', 0.13699622, 257],\n",
       "  ['ConsumerCourt_DCDRC_52148', '0', 0.14308992, 230],\n",
       "  ['ConsumerCourt_DCDRC_70186', '0', 0.3350037, 4],\n",
       "  ['ConsumerCourt_DCDRC_70341', '0', 0.31165537, 6],\n",
       "  ['ConsumerCourt_DCDRC_90054', '0', 0.06956695, 1143],\n",
       "  ['ConsumerCourt_SCDRC_28640', '1', 0.15771793, 162],\n",
       "  ['ConsumerCourt_SCDRC_64152', '0', 0.1562502, 170],\n",
       "  ['ConsumerCourt_SCDRC_68718', '1', 0.16174522, 146],\n",
       "  ['ConsumerCourt_SCDRC_70632', '0', 0.21051668, 64],\n",
       "  ['DelhiHC_2009_735', '1', 0.049783476, 2147],\n",
       "  ['DelhiHC_2012_372', '0', 0.019550774, 13957],\n",
       "  ['DelhiHC_2012_374', '0', 0.019550774, 13956],\n",
       "  ['SupremeCourt_1996_416', '0', 0.08286074, 802]],\n",
       " '7': [['ConsumerCourt_DCDRC_119406', '1', 0.07700122, 219],\n",
       "  ['ConsumerCourt_DCDRC_121344', '0', 0.08713765, 153],\n",
       "  ['ConsumerCourt_DCDRC_127019', '0', 0.09750148, 109],\n",
       "  ['ConsumerCourt_DCDRC_130205', '0', 0.20515528, 17],\n",
       "  ['ConsumerCourt_DCDRC_207672', '1', 0.15500039, 27],\n",
       "  ['ConsumerCourt_DCDRC_222487', '0', 0.26769084, 8],\n",
       "  ['ConsumerCourt_DCDRC_224805', '0', 0.08499279, 166],\n",
       "  ['ConsumerCourt_DCDRC_235755', '0', 0.10645334, 88],\n",
       "  ['ConsumerCourt_DCDRC_236026', '1', 0.18713242, 20],\n",
       "  ['ConsumerCourt_DCDRC_236229', '0', 0.4570618, 5],\n",
       "  ['ConsumerCourt_DCDRC_33939', '0', 0.14739224, 30],\n",
       "  ['ConsumerCourt_DCDRC_44337', '1', 0.12962462, 45],\n",
       "  ['ConsumerCourt_DCDRC_45534', '0', 0.58968306, 1],\n",
       "  ['ConsumerCourt_DCDRC_46470', '0', 0.29182968, 7],\n",
       "  ['ConsumerCourt_DCDRC_48811', '0', 0.124101706, 53],\n",
       "  ['ConsumerCourt_DCDRC_51454', '1', 0.121700026, 58],\n",
       "  ['ConsumerCourt_DCDRC_64180', '0', 0.58522964, 2],\n",
       "  ['ConsumerCourt_DCDRC_73953', '0', 0.13533789, 38],\n",
       "  ['ConsumerCourt_DCDRC_75554', '0', 0.0827841, 178],\n",
       "  ['ConsumerCourt_SCDRC_1050', '0', 0.12768492, 49],\n",
       "  ['ConsumerCourt_SCDRC_1387', '0', 0.5129691, 4],\n",
       "  ['ConsumerCourt_SCDRC_1418', '0', 0.34952796, 6],\n",
       "  ['ConsumerCourt_SCDRC_65323', '0', 0.15895015, 24],\n",
       "  ['ConsumerCourt_SCDRC_66203', '0', 0.035691578, 1494],\n",
       "  ['DelhiHC_2012_2026', '0', 0.22411771, 9]],\n",
       " '8': [['ConsumerCourt_DCDRC_101057', '1', 0.10931648, 18],\n",
       "  ['ConsumerCourt_DCDRC_118168', '0', 0.034153078, 1818],\n",
       "  ['ConsumerCourt_DCDRC_118989', '0', 0.10121461, 25],\n",
       "  ['ConsumerCourt_DCDRC_120003', '1', 0.047669776, 469],\n",
       "  ['ConsumerCourt_DCDRC_120004', '1', 0.048152998, 449],\n",
       "  ['ConsumerCourt_DCDRC_121058', '0', 0.049880885, 387],\n",
       "  ['ConsumerCourt_DCDRC_125286', '0', 0.05475113, 258],\n",
       "  ['ConsumerCourt_DCDRC_126274', '0', 0.03525163, 1574],\n",
       "  ['ConsumerCourt_DCDRC_128072', '1', 0.10268682, 23],\n",
       "  ['ConsumerCourt_DCDRC_129352', '0', 0.05383814, 280],\n",
       "  ['ConsumerCourt_DCDRC_129820', '0', 0.124922395, 11],\n",
       "  ['ConsumerCourt_DCDRC_131144', '0', 0.03183586, 2434],\n",
       "  ['ConsumerCourt_DCDRC_131587', '0', 0.051139213, 353],\n",
       "  ['ConsumerCourt_DCDRC_131846', '0', 0.019118095, 12926],\n",
       "  ['ConsumerCourt_DCDRC_132917', '0', 0.030200586, 2956],\n",
       "  ['ConsumerCourt_DCDRC_132928', '0', 0.09650337, 31],\n",
       "  ['ConsumerCourt_DCDRC_134709', '0', 0.15563917, 3],\n",
       "  ['ConsumerCourt_DCDRC_140632', '0', 0.08023442, 70],\n",
       "  ['ConsumerCourt_DCDRC_140644', '0', 0.035971686, 1444],\n",
       "  ['ConsumerCourt_DCDRC_145502', '0', 0.21882568, 1],\n",
       "  ['ConsumerCourt_DCDRC_169855', '0', 0.013309098, 30432],\n",
       "  ['ConsumerCourt_DCDRC_202901', '0', 0.010666257, 46726],\n",
       "  ['ConsumerCourt_DCDRC_203935', '0', 0.04931935, 408],\n",
       "  ['ConsumerCourt_DCDRC_222781', '0', 0.041030366, 866],\n",
       "  ['ConsumerCourt_DCDRC_223340', '0', 0.0984898, 29],\n",
       "  ['ConsumerCourt_DCDRC_228779', '0', 0.059722915, 175],\n",
       "  ['ConsumerCourt_DCDRC_229540', '0', 0.060987756, 165],\n",
       "  ['ConsumerCourt_DCDRC_39867', '0', 0.08580633, 56],\n",
       "  ['ConsumerCourt_DCDRC_40822', '0', 0.13299286, 10],\n",
       "  ['ConsumerCourt_DCDRC_41058', '0', 0.08600744, 55],\n",
       "  ['ConsumerCourt_DCDRC_41514', '0', 0.08399893, 59],\n",
       "  ['ConsumerCourt_DCDRC_57900', '1', 0.050087053, 383],\n",
       "  ['ConsumerCourt_DCDRC_69224', '0', 0.08091902, 66],\n",
       "  ['ConsumerCourt_DCDRC_71619', '0', 0.02780113, 3999],\n",
       "  ['ConsumerCourt_DCDRC_73864', '0', 0.06340193, 135],\n",
       "  ['ConsumerCourt_DCDRC_75339', '0', 0.085053116, 57],\n",
       "  ['ConsumerCourt_DCDRC_75574', '1', 0.028744778, 3540],\n",
       "  ['ConsumerCourt_DCDRC_76123', '0', 0.07817657, 71],\n",
       "  ['ConsumerCourt_DCDRC_85243', '0', 0.05827902, 196],\n",
       "  ['ConsumerCourt_SCDRC_29744', '0', 0.09364603, 37],\n",
       "  ['ConsumerCourt_SCDRC_33757', '0', 0.15049091, 4],\n",
       "  ['ConsumerCourt_SCDRC_53283', '0', 0.06380063, 131],\n",
       "  ['ConsumerCourt_SCDRC_63603', '0', 0.04523133, 570],\n",
       "  ['ConsumerCourt_SCDRC_66106', '1', 0.055392, 245],\n",
       "  ['ConsumerCourt_SCDRC_66890', '0', 0.040729888, 891],\n",
       "  ['ConsumerCourt_SCDRC_67067', '0', 0.036466334, 1361],\n",
       "  ['ConsumerCourt_SCDRC_67949', '0', 0.06639166, 116],\n",
       "  ['ConsumerCourt_SCDRC_67951', '0', 0.05266119, 305],\n",
       "  ['ConsumerCourt_SCDRC_72333', '1', 0.04983908, 388],\n",
       "  ['JodhpurHC_2008_1906', '0', 0.008238676, 70133]],\n",
       " '9': [['ConsumerCourt_DCDRC_108097', '0', 0.07101656, 1800],\n",
       "  ['ConsumerCourt_DCDRC_119856', '1', 0.1855714, 38],\n",
       "  ['ConsumerCourt_DCDRC_119986', '0', 0.22666712, 6],\n",
       "  ['ConsumerCourt_DCDRC_128297', '0', 0.052711163, 4346],\n",
       "  ['ConsumerCourt_DCDRC_128836', '0', 0.017190233, 70930],\n",
       "  ['ConsumerCourt_DCDRC_130625', '0', 0.026259042, 29493],\n",
       "  ['ConsumerCourt_DCDRC_133010', '0', 0.076752506, 1467],\n",
       "  ['ConsumerCourt_DCDRC_138306', '1', 0.2921061, 4],\n",
       "  ['ConsumerCourt_DCDRC_139625', '0', 0.15522379, 132],\n",
       "  ['ConsumerCourt_DCDRC_143537', '0', 0.1833765, 41],\n",
       "  ['ConsumerCourt_DCDRC_202901', '0', 0.00243948, 285072],\n",
       "  ['ConsumerCourt_DCDRC_202902', '0', 0.011053559, 134995],\n",
       "  ['ConsumerCourt_DCDRC_202903', '0', 0.009872075, 152611],\n",
       "  ['ConsumerCourt_DCDRC_222047', '1', 0.118984275, 410],\n",
       "  ['ConsumerCourt_DCDRC_224718', '1', 0.109472655, 535],\n",
       "  ['ConsumerCourt_DCDRC_226994', '0', 0.03822827, 11462],\n",
       "  ['ConsumerCourt_DCDRC_227115', '0', 0.12726915, 330],\n",
       "  ['ConsumerCourt_DCDRC_227445', '0', 0.095713474, 794],\n",
       "  ['ConsumerCourt_DCDRC_236013', '1', 0.31705767, 3],\n",
       "  ['ConsumerCourt_DCDRC_38039', '1', 0.32157362, 2],\n",
       "  ['ConsumerCourt_DCDRC_38552', '0', 0.19962743, 18],\n",
       "  ['ConsumerCourt_DCDRC_45418', '0', 0.33407182, 1],\n",
       "  ['ConsumerCourt_DCDRC_53237', '1', 0.13149814, 287],\n",
       "  ['ConsumerCourt_DCDRC_56957', '0', 0.1695722, 76],\n",
       "  ['ConsumerCourt_DCDRC_89958', '0', 0.0652692, 2270],\n",
       "  ['ConsumerCourt_NCDRC_2916', '0', 0.15453728, 134],\n",
       "  ['ConsumerCourt_NCDRC_437', '0', 0.016535986, 75833],\n",
       "  ['ConsumerCourt_SCDRC_40659', '0', 0.15831865, 121],\n",
       "  ['ConsumerCourt_SCDRC_49689', '0', 0.065745026, 2218],\n",
       "  ['ConsumerCourt_SCDRC_53178', '0', 0.08437232, 1165],\n",
       "  ['ConsumerCourt_SCDRC_65050', '0', 0.2848596, 5],\n",
       "  ['ConsumerCourt_SCDRC_67634', '0', 0.017923096, 65838],\n",
       "  ['ConsumerCourt_SCDRC_68803', '0', 0.12768802, 325],\n",
       "  ['DelhiHC_2008_1343', '0', 0.027151834, 27254],\n",
       "  ['DelhiHC_2009_453', '0', 0.02004609, 52820],\n",
       "  ['DelhiHC_2010_4683', '0', 0.04252152, 8466],\n",
       "  ['DelhiHC_2010_6192', '0', 0.051371463, 4717],\n",
       "  ['DelhiHC_2011_69', '0', 0.017098067, 71626],\n",
       "  ['DelhiHC_2013_811', '0', 0.022599204, 41128],\n",
       "  ['SupremeCourt_2008_278', '0', 0.012008673, 121955]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'W2V_SG_IDF'\n",
    "\n",
    "with open('py_results/' + model_name + 'sim_list.pkl', 'wb') as output:\n",
    "    pickle.dump(sim_list, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open('py_results/' + model_name + 'rank_list.pkl', 'wb') as output:\n",
    "    pickle.dump(rank_list, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store results in 1st sheet\n",
    "\n",
    "\n",
    "wb = Workbook()\n",
    "dest_filename = 'result_excel/' + model_name + '.xlsx'\n",
    "ws1 = wb.active\n",
    "ws1.title = \"ground_truth\"\n",
    "ws1.append(['Query','Filename', 'Relevance', 'Score', 'Rank'])\n",
    "for key,value in results.iteritems():\n",
    "    for i in value:\n",
    "        ws1.append([int(key)]+ i)\n",
    "\n",
    "wb.save(filename = dest_filename)\n",
    "\n",
    "#Query wise (F score)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "f = pd.ExcelFile(dest_filename)\n",
    "\n",
    "from scipy.stats import hmean\n",
    "\n",
    "\n",
    "\n",
    "places = 4\n",
    "wb = load_workbook(dest_filename)\n",
    "ws1 = wb.create_sheet(title=\"evaluation_Qwise\")\n",
    "\n",
    "ws1.append(['Query','Docs considered', 'Precision/Recall', 'Model', 1, 5 ,10, 25, 50, 100, 500, 1000])\n",
    "\n",
    "k = [1.0, 5.0 ,10.0, 25.0, 50.0, 100.0, 500.0, 1000.0]\n",
    "for sheet in f.sheet_names:\n",
    "    if(sheet == \"evaluation\"):\n",
    "        continue\n",
    "    for q in np.arange(1,11):\n",
    "\n",
    "        x = f.parse(sheet)\n",
    "        x = x[x['Query'] == q]\n",
    "        total_1 = (float)(x[x['Relevance'] == 1].shape[0])\n",
    "        total_0 = (float)(x[x['Relevance'] == 0].shape[0])\n",
    "        total = (float)(x.shape[0])\n",
    "        \n",
    "        ####  repitition due to complication in considering both 1 & 0 relevance\n",
    "        # precision 1\n",
    "        row = [q, 1, 'P', model_name ]\n",
    "        for i in k:\n",
    "            row.append(x[np.logical_and(x['Relevance'] == 1 , x['Rank'] <= i)].shape[0]/i)\n",
    "        ws1.append(row);\n",
    "        p1 = row;\n",
    "        # precision 0\n",
    "        row = [q, 0, 'P', model_name ]\n",
    "        for i in k:\n",
    "            row.append(x[np.logical_and(x['Relevance'] == 0 , x['Rank'] <= i)].shape[0]/i)    \n",
    "        ws1.append(row);\n",
    "        p0 = row;\n",
    "        #precision 10\n",
    "        row = [q, 10, 'P', model_name]\n",
    "        for i in k:\n",
    "            row.append(x[x['Rank'] <= i].shape[0]/i)  \n",
    "        ws1.append(row);\n",
    "        p10 = row;  \n",
    "        \n",
    "        \n",
    "        # recall 1\n",
    "        row = [q, 1, 'R', model_name]\n",
    "        for i in k:\n",
    "            row.append(x[np.logical_and(x['Relevance'] == 1 , x['Rank'] <= i)].shape[0]/total_1)\n",
    "            row[-1] = round(row[-1],places)\n",
    "        ws1.append(row);\n",
    "        r1 = row;    \n",
    "        # recall 0\n",
    "        row = [q, 0, 'R', model_name ]\n",
    "        for i in k:\n",
    "            row.append(x[np.logical_and(x['Relevance'] == 0 , x['Rank'] <= i)].shape[0]/total_0)\n",
    "            row[-1] = round(row[-1],places)\n",
    "        ws1.append(row);\n",
    "        r0 = row;\n",
    "        #recall 10\n",
    "        row = [q, 10, 'R', model_name ]\n",
    "        for i in k:\n",
    "            row.append(x[x['Rank'] <= i].shape[0]/total)\n",
    "            row[-1] = round(row[-1],places)\n",
    "        ws1.append(row);\n",
    "        r10 = row;      \n",
    "\n",
    "\n",
    "        # F 1\n",
    "        row = [q, 1, 'F', model_name ]\n",
    "        for i in range(-len(k), 0, 1):\n",
    "            if p1[i] == 0.0 :\n",
    "                row.append(0.0)\n",
    "            else:\n",
    "                row.append(hmean([p1[i],r1[i]]))\n",
    "            row[-1] = round(row[-1],places)\n",
    "        ws1.append(row);\n",
    "\n",
    "        # F 0\n",
    "        row = [q, 0, 'F', model_name]\n",
    "        for i in range(-len(k), 0, 1):\n",
    "            if p0[i] == 0.0:\n",
    "                row.append(0.0)\n",
    "            else:\n",
    "                row.append(hmean([p0[i],r0[i]]))\n",
    "            row[-1] = round(row[-1],places)\n",
    "        ws1.append(row);\n",
    "\n",
    "        # F 10\n",
    "        row = [q, 10, 'F', model_name]\n",
    "        for i in range(-len(k), 0, 1):\n",
    "            if p10[i] == 0.0:\n",
    "                row.append(0.0)\n",
    "            else:\n",
    "                row.append(hmean([p10[i],r10[i]]))\n",
    "            row[-1] = round(row[-1],places)\n",
    "        ws1.append(row);\n",
    "        \n",
    "wb.save(filename = dest_filename)\n",
    "\n",
    "\n",
    "#Query wise Average precision\n",
    "# precision sum\n",
    "def p_sum(z):\n",
    "    z = z.copy()  \n",
    "    z.sort_values(inplace=True)\n",
    "    result = 0\n",
    "    for i,val in enumerate(z):\n",
    "        result += (i+1)/float(val) \n",
    "    return result\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "f = pd.ExcelFile(dest_filename)\n",
    "\n",
    "from scipy.stats import hmean\n",
    "\n",
    "\n",
    "places = 4\n",
    "wb = load_workbook(dest_filename)\n",
    "ws1 = wb.create_sheet(title=\"AP_Qwise\")\n",
    "\n",
    "ws1.append(['Query','Docs considered', 'Precision/Recall', 'Model', 1, 5 ,10, 25, 50, 100, 500, 1000])\n",
    "\n",
    "\n",
    "for sheet in f.sheet_names:    \n",
    "    if(sheet == \"evaluation\"or sheet == \"evaluation_Qwise\"):\n",
    "        continue\n",
    "    for q in np.arange(1,11):\n",
    "        x = f.parse(sheet)\n",
    "        x = x[x['Query'] == q]\n",
    "        total = {}\n",
    "        total[1] = (float)(x[x['Relevance'] == 1].shape[0])\n",
    "        total[0] = (float)(x[x['Relevance'] == 0].shape[0])\n",
    "        total[10] = (float)(x.shape[0])\n",
    "        \n",
    "        for rel in [1,0]:\n",
    "            # precision 1\n",
    "            row = [q, rel, 'AP', model_name ]\n",
    "            for i in [1.0, 5.0, 10.0, 25.0, 50.0, 100.0, 500.0, 1000.0]:\n",
    "                row.append(p_sum(x[np.logical_and(x['Relevance'] == rel, x['Rank'] <= i)]['Rank'])/total[rel])\n",
    "            ws1.append(row);\n",
    "\n",
    "        row = [q, 10, 'AP', model_name ]\n",
    "        for i in [1.0, 5.0, 10.0, 25.0, 50.0, 100.0, 500.0, 1000.0]:\n",
    "            row.append(p_sum(x[x['Rank'] <= i]['Rank'])/total[10])\n",
    "        ws1.append(row);\n",
    "wb.save(filename = dest_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    Parameters:\n",
    "      filename : File path or existing ExcelWriter\n",
    "                 (Example: '/path/to/file.xlsx')\n",
    "      df : dataframe to save to workbook\n",
    "      sheet_name : Name of sheet which will contain DataFrame.\n",
    "                   (default: 'Sheet1')\n",
    "      startrow : upper left cell row to dump data frame.\n",
    "                 Per default (startrow=None) calculate the last row\n",
    "                 in the existing DF and write to the next row...\n",
    "      truncate_sheet : truncate (remove and recreate) [sheet_name]\n",
    "                       before writing DataFrame to Excel file\n",
    "      to_excel_kwargs : arguments which will be passed to `DataFrame.to_excel()`\n",
    "                        [can be dictionary]\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "    try:\n",
    "        # try to open an existing workbook\n",
    "        writer.book = load_workbook(filename)\n",
    "\n",
    "        # get the last row in the existing Excel sheet\n",
    "        # if it was not specified explicitly\n",
    "        if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "            startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "        # truncate sheet\n",
    "        if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "            # index of [sheet_name] sheet\n",
    "            idx = writer.book.sheetnames.index(sheet_name)\n",
    "            # remove [sheet_name]\n",
    "            writer.book.remove(writer.book.worksheets[idx])\n",
    "            # create an empty sheet [sheet_name] using old index\n",
    "            writer.book.create_sheet(sheet_name, idx)\n",
    "\n",
    "        # copy existing sheets\n",
    "        writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    except FileNotFoundError:\n",
    "        # file does not exist yet, we will create it\n",
    "        pass\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, index= False, header = False, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()\n",
    "\n",
    "    \n",
    "f = pd.ExcelFile(dest_filename)\n",
    "sec_dest = 'result_excel/all_results.xlsx'\n",
    "f2 = pd.ExcelFile(sec_dest)\n",
    "append_df_to_excel(sec_dest, f.parse(1), sheet_name= f2.sheet_names[0])\n",
    "append_df_to_excel(sec_dest, f.parse(2), sheet_name= f2.sheet_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Top_x(x, R):\n",
    "    R = list(R)\n",
    "    x_names = []\n",
    "    for i in range(x):\n",
    "        x_names.append(filenames[R.index(i + 1)].strip('.txt'))\n",
    "    return x_names\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_stat(word, freq, index):\n",
    "    index_doc = dict(bm25.corpus[index])\n",
    "    word = dictionary.doc2bow([word])[0][0]\n",
    "    idf = bm25.idf[word] if bm25.idf[word] >= 0 else EPSILON * average_idf\n",
    "    score = freq*((idf * index_doc[word] * (PARAM_K1 + 1)\n",
    "              / (index_doc[word] + PARAM_K1 * (1 - PARAM_B + PARAM_B * doc_len[index] / bm25.avgdl))))\n",
    "    return (index_doc[word], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wb = Workbook()\n",
    "dest_filename = 'Temp.xlsx'\n",
    "ws = wb.active\n",
    "ws.title = \"Blank\"\n",
    "#ws.append([(2.2,2.2)])\n",
    "wb.save(filename = dest_filename)\n",
    "def common_words(q, F):\n",
    "    temp = []\n",
    "    for word, freq in dictionary.doc2bow(queries[q]) :\n",
    "        temp.append((dictionary[word], freq, round(bm25.idf[word], 2)))\n",
    "    temp.sort(key=lambda x: (x[2],x[1]), reverse=True)\n",
    "    q_words = [i[0]  for i in temp]\n",
    "    q_freq = [i[1]  for i in temp]\n",
    "    index = filenames.index(F + '.txt')\n",
    "    index_doc = dict(bm25.corpus[index])\n",
    "    row = []\n",
    "    for word, freq in  zip(q_words, q_freq):\n",
    "        w = dictionary.doc2bow([word])[0][0]\n",
    "        if w in index_doc: \n",
    "            f, s = score_stat(word, freq, index)\n",
    "            row.append([word + ', ' + str(round(bm25.idf[w], 2)), freq, f,  round( (s*100)/sim_list[q][index], 1)])  \n",
    "    row.sort(key = lambda x: (x[3],x[1],x[2]), reverse = True)\n",
    "    wb = load_workbook('Temp.xlsx')\n",
    "    ws = wb.create_sheet(title=str(q) + F)\n",
    "    ws.append(['word,idf', 'Query freq', 'freq', '% score'])\n",
    "    for i in row:\n",
    "        ws.append(i)\n",
    "    wb.save(filename = 'Temp.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"toberead.txt\", 'r') \n",
    "count = 0\n",
    "q = 1\n",
    "for i in f:\n",
    "    if i == '\\n':\n",
    "        continue\n",
    "    count = count + 1\n",
    "    common_words(q, i.strip())\n",
    "    if count % 5 == 0:\n",
    "        q = q + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in files_to_tokens(full_filenames[filenames.index(doc + '.txt')]):\n",
    "    for j in i:\n",
    "        print j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = 'ConsumerCourt_SCDRC_30176'\n",
    "corpus[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "common_words(1, 'ConsumerCourt_DCDRC_41588')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index= None, columns=['words','pair'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.append(['lol', ('we','wew')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uncommon_words(q, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store results in 1st sheet\n",
    "wb = Workbook()\n",
    "dest_filename = 'Explore_BM25.xlsx'\n",
    "ws = wb.active\n",
    "ws.title = \"Blank\"\n",
    "#ws.append([(2.2,2.2)])\n",
    "wb.save(filename = dest_filename)\n",
    "\n",
    "wb = load_workbook('Explore_BM25.xlsx')\n",
    "\n",
    "for q in range(1, 11):\n",
    "    ws = wb.create_sheet(title=\"q\" + str(q))\n",
    "    #x_names = Top_x(10, rank_list[q])\n",
    "    top_row = ['Doc Name', 'Rel', 'Doc Length', ' Rank', 'Score']\n",
    "    sec_row = [' ']*5\n",
    "    temp = []\n",
    "    for word, freq in dictionary.doc2bow(queries[q]) :\n",
    "        temp.append((dictionary[word], freq, round(bm25.idf[word], 2)))\n",
    "    temp.sort(key=lambda x: (x[2],x[1]), reverse=True)\n",
    "    ws.append(top_row + [i[0]  for i in temp])\n",
    "    ws.append(sec_row + [str(i[1]) + ', ' + str(i[2]) for i in temp])\n",
    "    q_words = [i[0]  for i in temp]\n",
    "    q_freq = [i[1]  for i in temp]\n",
    "    \n",
    "    #continue\n",
    "    doc_list = [i[0] for i in query_truth[str(q)]] + Top_x(10, rank_list[q])\n",
    "    doc_list = list((set(doc_list)))\n",
    "    doc_list.sort(key = lambda doc : rank_list[q][filenames.index(doc + '.txt')])\n",
    "    doc_row = []\n",
    "    for doc in doc_list:\n",
    "        temp  = [doc]\n",
    "        rel_dic = dict(query_truth[str(q)])\n",
    "        if doc in rel_dic:\n",
    "            temp.append(rel_dic[doc])\n",
    "        else:\n",
    "            temp.append('Not')\n",
    "        temp.append(doc_len[filenames.index(doc + '.txt')])\n",
    "        temp.append(rank_list[q][filenames.index(doc + '.txt')])\n",
    "        temp.append(round(sim_list[q][filenames.index(doc + '.txt')], 2))\n",
    "        doc_row.append(temp)\n",
    "\n",
    "    for row in doc_row:\n",
    "        index = filenames.index(row[0] + '.txt')\n",
    "        index_doc = dict(bm25.corpus[index])\n",
    "        \n",
    "        for word, freq in  zip(q_words, q_freq):\n",
    "            if dictionary.doc2bow([word])[0][0] in index_doc: \n",
    "                f, s = score_stat(word, freq, index)\n",
    "                row.append( str(f) + ', ' +  str(round( (s*100)/sim_list[q][index], 1) ))\n",
    "            else:\n",
    "                row.append('X')\n",
    "        ws.append(row)\n",
    "        ws.append([])        \n",
    "wb.save(filename = dest_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store results in 1st sheet\n",
    "wb = Workbook()\n",
    "dest_filename = 'Explore_BM25_uncom.xlsx'\n",
    "ws = wb.active\n",
    "ws.title = \"Blank\"\n",
    "#ws.append([(2.2,2.2)])\n",
    "wb.save(filename = dest_filename)\n",
    "\n",
    "\n",
    "\n",
    "wb = load_workbook('Explore_BM25_uncom.xlsx')\n",
    "\n",
    "for q in range(1, 11):\n",
    "    ws = wb.create_sheet(title=\"q\" + str(q))\n",
    "    #x_names = Top_x(10, rank_list[q])\n",
    "    top_row = ['Doc Name', 'Rel', 'Doc Length', ' Rank', 'Score']\n",
    "    sec_row = [' ']*5\n",
    "    temp = []\n",
    "    for word, freq in dictionary.doc2bow(queries[q]) :\n",
    "        temp.append((dictionary[word], freq, round(bm25.idf[word], 2)))\n",
    "    temp.sort(key=lambda x: (x[2],x[1]), reverse=True)\n",
    "    ws.append(top_row + [i[0]  for i in temp])\n",
    "    ws.append(sec_row + [str(i[1]) + ', ' + str(i[2]) for i in temp])\n",
    "    q_words = [i[0]  for i in temp]\n",
    "    q_freq = [i[1]  for i in temp]\n",
    "    \n",
    "    #continue\n",
    "    doc_list = [i[0] for i in query_truth[str(q)]] + Top_x(10, rank_list[q])\n",
    "    doc_list = list((set(doc_list)))\n",
    "    doc_list.sort(key = lambda doc : rank_list[q][filenames.index(doc + '.txt')])\n",
    "    doc_row = []\n",
    "    for doc in doc_list:\n",
    "        temp  = [doc]\n",
    "        rel_dic = dict(query_truth[str(q)])\n",
    "        if doc in rel_dic:\n",
    "            temp.append(rel_dic[doc])\n",
    "        else:\n",
    "            temp.append('Not')\n",
    "        temp.append(doc_len[filenames.index(doc + '.txt')])\n",
    "        temp.append(rank_list[q][filenames.index(doc + '.txt')])\n",
    "        temp.append(round(sim_list[q][filenames.index(doc + '.txt')], 2))\n",
    "        doc_row.append(temp)\n",
    "\n",
    "    for row in doc_row:\n",
    "        index = filenames.index(row[0] + '.txt')\n",
    "        index_doc = dict(bm25.corpus[index])\n",
    "        \n",
    "#         for word, freq in  zip(q_words, q_freq):\n",
    "#             if dictionary.doc2bow([word])[0][0] in index_doc: \n",
    "#                 f, s = score_stat(word, freq, index)\n",
    "#                 row.append( str(f) + ', ' +  str(round( (s*100)/sim_list[q][index], 1) ))\n",
    "#             else:\n",
    "#                 row.append('X')\n",
    "        #ws.append(row)\n",
    "        \n",
    "        sec_row = [' ']*5\n",
    "        temp = []\n",
    "        for word, freq in index_doc.iteritems():\n",
    "            if dictionary[word] not in q_words:\n",
    "                temp.append((dictionary[word], freq, round(bm25.idf[word], 2)))\n",
    "        ws.append(row + [i[0]  for i in temp])\n",
    "        ws.append(sec_row + [str(i[1]) + ', ' + str(i[2]) for i in temp])\n",
    "        ws.append([])        \n",
    "wb.save(filename = dest_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store results in 1st sheet\n",
    "wb = Workbook()\n",
    "dest_filename = 'Explore_BM25_all.xlsx'\n",
    "ws = wb.active\n",
    "ws.title = \"Blank\"\n",
    "#ws.append([(2.2,2.2)])\n",
    "wb.save(filename = dest_filename)\n",
    "\n",
    "\n",
    "\n",
    "wb = load_workbook('Explore_BM25_all.xlsx')\n",
    "\n",
    "for q in range(1, 11):\n",
    "    ws = wb.create_sheet(title=\"q\" + str(q))\n",
    "    #x_names = Top_x(10, rank_list[q])\n",
    "    top_row = ['Doc Name', 'Rel', 'Doc Length', ' Rank', 'Score']\n",
    "    sec_row = [' ']*5\n",
    "    temp = []\n",
    "    for word, freq in dictionary.doc2bow(queries[q]) :\n",
    "        temp.append((dictionary[word], freq, round(bm25.idf[word], 2)))\n",
    "    temp.sort(key=lambda x: (x[2],x[1]), reverse=True)\n",
    "    ws.append(top_row + [i[0]  for i in temp])\n",
    "    ws.append(sec_row + [str(i[1]) + ', ' + str(i[2]) for i in temp])\n",
    "    q_words = [i[0]  for i in temp]\n",
    "    q_freq = [i[1]  for i in temp]\n",
    "    \n",
    "    #continue\n",
    "    doc_list = [i[0] for i in query_truth[str(q)]] + Top_x(10, rank_list[q])\n",
    "    doc_list = list((set(doc_list)))\n",
    "    doc_list.sort(key = lambda doc : rank_list[q][filenames.index(doc + '.txt')])\n",
    "    doc_row = []\n",
    "    for doc in doc_list:\n",
    "        temp  = [doc]\n",
    "        rel_dic = dict(query_truth[str(q)])\n",
    "        if doc in rel_dic:\n",
    "            temp.append(rel_dic[doc])\n",
    "        else:\n",
    "            temp.append('Not')\n",
    "        temp.append(doc_len[filenames.index(doc + '.txt')])\n",
    "        temp.append(rank_list[q][filenames.index(doc + '.txt')])\n",
    "        temp.append(round(sim_list[q][filenames.index(doc + '.txt')], 2))\n",
    "        doc_row.append(temp)\n",
    "\n",
    "    for row in doc_row:\n",
    "        index = filenames.index(row[0] + '.txt')\n",
    "        index_doc = dict(bm25.corpus[index])\n",
    "        \n",
    "        for word, freq in  zip(q_words, q_freq):\n",
    "            if dictionary.doc2bow([word])[0][0] in index_doc: \n",
    "                f, s = score_stat(word, freq, index)\n",
    "                row.append( str(f) + ', ' +  str(round( (s*100)/sim_list[q][index], 1) ))\n",
    "            else:\n",
    "                row.append('X')\n",
    "        ws.append(row)\n",
    "        \n",
    "        sec_row = [' ']*5\n",
    "        temp = []\n",
    "        for word, freq in index_doc.iteritems():\n",
    "            if dictionary[word] not in q_words:\n",
    "                temp.append((dictionary[word], freq, round(bm25.idf[word], 2)))\n",
    "        ws.append(sec_row + [i[0]  for i in temp])\n",
    "        ws.append(sec_row + [str(i[1]) + ', ' + str(i[2]) for i in temp])\n",
    "        ws.append([])        \n",
    "wb.save(filename = dest_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
